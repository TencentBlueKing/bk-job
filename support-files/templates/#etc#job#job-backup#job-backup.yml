spring:
  application:
    name: job-backup
  cloud:
    stream:
      defaultBinder: jobCommon
      binders:
        jobCommon:
          type: rabbit
          environment:
            spring:
              rabbitmq:
                host: __BK_JOB_RABBITMQ_HOST__
                port: __BK_JOB_RABBITMQ_PORT__
                username: __BK_JOB_RABBITMQ_USERNAME__
                password: __BK_JOB_RABBITMQ_PASSWORD__
                virtual-host: __BK_JOB_RABBITMQ_VHOST__
  datasource:
    job-backup:
      driver-class-name: io.opentelemetry.instrumentation.jdbc.OpenTelemetryDriver
      type: com.zaxxer.hikari.HikariDataSource
      jdbc-url: jdbc:otel:mysql://__BK_JOB_BACKUP_MYSQL_HOST__:__BK_JOB_BACKUP_MYSQL_PORT__/job_backup?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
      username: __BK_JOB_BACKUP_MYSQL_USERNAME__
      password: __BK_JOB_BACKUP_MYSQL_PASSWORD__
      maximum-pool-size: 20
      minimum-idle: 5
      idle-timeout: 600000
      poolName: "job-backup"
      validationTimeout: 5000
    job-execute:
      driver-class-name: io.opentelemetry.instrumentation.jdbc.OpenTelemetryDriver
      type: com.zaxxer.hikari.HikariDataSource
      jdbc-url: jdbc:otel:mysql://__BK_JOB_EXECUTE_MYSQL_HOST__:__BK_JOB_EXECUTE_MYSQL_PORT__/job_execute?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
      username: __BK_JOB_EXECUTE_MYSQL_USERNAME__
      password: __BK_JOB_EXECUTE_MYSQL_PASSWORD__
      maximum-pool-size: 10
      minimum-idle: 2
      idle-timeout: 6000
      poolName: "job-execute"
      validationTimeout: 5000
    # 执行日志mongodb数据源
    job-execute-mongodb:
      uri: __BK_JOB_LOGSVR_MONGODB_URI__
    # 执行数据归档DB配置，若需开启数据归档请去除注释并添加相应环境变量进行配置
    #job-execute-archive:
      #driver-class-name: io.opentelemetry.instrumentation.jdbc.OpenTelemetryDriver
      #type: com.zaxxer.hikari.HikariDataSource
      #jdbc-url: jdbc:otel:mysql://__BK_JOB_EXECUTE_ARCHIVE_MYSQL_HOST__:__BK_JOB_EXECUTE_ARCHIVE_MYSQL_PORT__/job_execute?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
      #username: __BK_JOB_EXECUTE_ARCHIVE_MYSQL_USERNAME__
      #password: __BK_JOB_EXECUTE_ARCHIVE_MYSQL_PASSWORD__
      #maximum-pool-size: 10
      #minimum-idle: 2
      #idle-timeout: 6000
      #poolName: "job-execute-archive"
      #validationTimeout: 5000
  redis:
    {# 社区版默认配置 -#}
    {% if job_edition != "ee" -%}
    # 使用单机Redis时的配置项
    host: __BK_JOB_BACKUP_REDIS_HOST__
    port: __BK_JOB_BACKUP_REDIS_PORT__
    # 使用Redis Sentinel时的配置项
    #sentinel:
      #password: __BK_JOB_BACKUP_REDIS_SENTINEL_PASSWORD__
      #master: __BK_JOB_BACKUP_REDIS_SENTINEL_MASTER__
      #nodes: __BK_JOB_BACKUP_REDIS_SENTINEL_NODES__
    {% endif -%}
    {# 企业版默认配置 -#}
    {% if job_edition == "ee" -%}
    # 使用单机Redis时的配置项
    #host: __BK_JOB_BACKUP_REDIS_HOST__
    #port: __BK_JOB_BACKUP_REDIS_PORT__
    # 使用Redis Sentinel时的配置项
    sentinel:
      password: __BK_JOB_BACKUP_REDIS_SENTINEL_PASSWORD__
      master: __BK_JOB_BACKUP_REDIS_SENTINEL_MASTER__
      nodes: __BK_JOB_BACKUP_REDIS_SENTINEL_NODES__
    {% endif -%}
    password: __BK_JOB_BACKUP_REDIS_PASSWORD__
    database: 0
    lettuce:
      pool:
        min-idle: 5
        max-idle: 10
        max-active: 8
        max-wait: 1ms
      shutdown-timeout: 100ms
  servlet:
    multipart:
      max-file-size: 5GB
      max-request-size: 5GB

job:
  backup:
    # `导入导出`存储后端默认为本地NFS
    storage-backend: local
    # 存储后端为蓝鲸制品库时的配置
    # storage-backend: artifactory
    # artifactory:
    #   repo: backup
    # DB 归档配置
    archive:
      # job-execute db 归档配置
      execute:
        # 是否启用 DB 归档
        enabled: false
        # 归档模式。deleteOnly: 仅删除；backupThenDelete: 先备份数据再删除。默认 deleteOnly
        mode: deleteOnly
        # 归档任务运行的cron表达式，默认每天凌晨04:00
        cron: 0 0 4 * * *
        # 热库中的数据保留时间（天）
        keep-days: 30
        # 归档数据读取时每次读取的数据量（单个表），服务内存受限时可适当降低该值
        read_id_step_size: 1000
        # 归档数据写入归档库时每次写入的数据量（单个表），服务内存受限时可适当降低该值
        batch_insert_row_size: 1000




