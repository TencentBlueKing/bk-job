spring:
  application:
    name: job-execute
  cloud:
    stream:
      bindings:
        taskInput:
          destination: task
          group: service.job.execute
          consumer:
            concurrency: 5
        taskOutput:
          destination: task
          group: service.job.execute
          consumer:
            concurrency: 5
        stepInput:
          destination: step
          group: service.job.execute
          consumer:
            concurrency: 5
        stepOutput:
          destination: step
          group: service.job.execute
          consumer:
            concurrency: 5
        gseTaskInput:
          destination: gse.task
          group: service.job.execute
          consumer:
            concurrency: 10
        gseTaskOutput:
          destination: gse.task
          group: service.job.execute
          consumer:
            concurrency: 10
        taskResultHandleResumeInput:
          destination: result.handle.task.resume
          group: service.job.execute
          consumer:
            concurrency: 5
        taskResultHandleResumeOutput:
          destination: result.handle.task.resume
          group: service.job.execute
          consumer:
            concurrency: 5
        notifyMsgInput:
          destination: notify.msg
          group: service.job.execute
          consumer:
            concurrency: 5
        notifyMsgOutput:
          destination: notify.msg
          group: service.job.execute
          consumer:
            concurrency: 5
        callbackInput:
          destination: task.callback
          group: service.job.execute
          consumer:
            concurrency: 5
        callbackOutput:
          destination: task.callback
          group: service.job.execute
          consumer:
            concurrency: 5
        taskStatisticsInput:
          destination: statistics.task
          group: service.job.execute
          consumer:
            concurrency: 5
        taskStatisticsOutput:
          destination: statistics.task
          group: service.job.execute
          consumer:
            concurrency: 5
      rabbit:
        bindings:
          taskInput:
            consumer:
              maxConcurrency: 10
          taskOutput:
            consumer:
              maxConcurrency: 10
          stepInput:
            consumer:
              maxConcurrency: 10
          stepOutput:
            consumer:
              maxConcurrency: 10
          gseTaskInput:
            consumer:
              maxConcurrency: 20
          gseTaskOutput:
            consumer:
              maxConcurrency: 20
          taskResultHandleResumeInput:
            consumer:
              maxConcurrency: 10
          taskResultHandleResumeOutput:
            consumer:
              maxConcurrency: 10
          notifyMsgInput:
            consumer:
              maxConcurrency: 10
          notifyMsgOutput:
            consumer:
              maxConcurrency: 10
          callbackInput:
            consumer:
              maxConcurrency: 10
          callbackOutput:
            consumer:
              maxConcurrency: 10
          taskStatisticsInput:
            consumer:
              maxConcurrency: 10
          taskStatisticsOutput:
            consumer:
              maxConcurrency: 10
  datasource:
    job-execute:
      driver-class-name: io.opentelemetry.instrumentation.jdbc.OpenTelemetryDriver
      type: com.zaxxer.hikari.HikariDataSource
      jdbc-url: jdbc:otel:mysql://__BK_JOB_EXECUTE_MYSQL_HOST__:__BK_JOB_EXECUTE_MYSQL_PORT__/job_execute?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
      username: __BK_JOB_EXECUTE_MYSQL_USERNAME__
      password: __BK_JOB_EXECUTE_MYSQL_PASSWORD__
      maximum-pool-size: 100
      minimum-idle: 20
      idle-timeout: 600000
      poolName: "job-execute"
      validationTimeout: 5000
  rabbitmq:
    host: __BK_JOB_EXECUTE_RABBITMQ_HOST__
    port: __BK_JOB_EXECUTE_RABBITMQ_PORT__
    username: __BK_JOB_EXECUTE_RABBITMQ_USERNAME__
    password: __BK_JOB_EXECUTE_RABBITMQ_PASSWORD__
    virtual-host: __BK_JOB_EXECUTE_RABBITMQ_VHOST__
  redis:
    {# 社区版默认配置 -#}
    {% if job_edition != "ee" -%}
    # 使用单机Redis时的配置项
    host: __BK_JOB_EXECUTE_REDIS_HOST__
    port: __BK_JOB_EXECUTE_REDIS_PORT__
    # 使用Redis Sentinel时的配置项
    #sentinel:
      #password: __BK_JOB_EXECUTE_REDIS_SENTINEL_PASSWORD__
      #master: __BK_JOB_EXECUTE_REDIS_SENTINEL_MASTER__
      #nodes: __BK_JOB_EXECUTE_REDIS_SENTINEL_NODES__
    {% endif -%}
    {# 企业版默认配置 -#}
    {% if job_edition == "ee" -%}
    # 使用单机Redis时的配置项
    #host: __BK_JOB_EXECUTE_REDIS_HOST__
    #port: __BK_JOB_EXECUTE_REDIS_PORT__
    # 使用Redis Sentinel时的配置项
    sentinel:
      password: __BK_JOB_EXECUTE_REDIS_SENTINEL_PASSWORD__
      master: __BK_JOB_EXECUTE_REDIS_SENTINEL_MASTER__
      nodes: __BK_JOB_EXECUTE_REDIS_SENTINEL_NODES__
    {% endif -%}
    password: __BK_JOB_EXECUTE_REDIS_PASSWORD__
    database: 0
    lettuce:
      pool:
        min-idle: 5
        max-idle: 10
        max-active: 8
        max-wait: 1ms
      shutdown-timeout: 100ms


feign:
  client:
    config:
      default:
        connectTimeout: 5000
        readTimeout: 5000
      sync:
        connectTimeout: 5000
        readTimeout: 30000
      log:
        connectTimeout: 5000
        readTimeout: 30000

# 执行日志导出产生的临时文件相关配置
log-export:
  # 存储后端：
  # local表示存储于本地NFS
  # artifactory表示存储于蓝鲸制品库，需要环境中部署有蓝鲸制品库
  storage-backend: local
  # 存储后端为蓝鲸制品库时的配置
  # storage-backend: artifactory
  # artifactory:
  #   # 存储执行日志导出临时文件的仓库名称
  #   repo: filedata
